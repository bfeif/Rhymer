{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "this notebook is an initial exploration into training the word embeddings like glove does....what are my concerns so far:\n",
    "- does word coocurrence (what GLOVE is meant for) have different phenomenology to similarity? i mean just in terms of general cdf...\n",
    "- does the decimal value of similarity metric work? It should. It should be equivalent to just multiplying ever similarity by 10 (or the exponent of the lowest similarity (which i'm pretty sure is .2 ...))\n",
    "\n",
    "we'll see. Here i want to implement the embedding layer architecture that kirill suggested...i can pass in word pairs and get dot product of their embeddings? not sure how to do that. we'll see\n",
    "how will i know when i'm done? perhaps if i can reproduce the results from just the sim_vectors from the 'cdf_of_typical_word' notebook...i.e. information is not lost in the dimensionality reduction....i can look at the glove paper to see how they did it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import utils\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from scipy.sparse import lil_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import progressbar\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = open('../data/cmudict.dict').readlines()\n",
    "\n",
    "# convert to word/sequence pairs:\n",
    "splitted = [i.replace('\\n', '').split(' ') for i in data]\n",
    "splitted = random.sample([i.replace('\\n', '').split(' ') for i in data], 2000)\n",
    "word_seq_pairs = {i[0]: (index, i[1:]) for index, i in enumerate(splitted)}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "make the distance metric....this is going to be some intensive shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2000 of 2000) |#####################| Elapsed Time: 0:02:02 Time: 0:02:02\n"
     ]
    }
   ],
   "source": [
    "dist = lil_matrix((len(word_seq_pairs), len(word_seq_pairs)), dtype=np.bool)\n",
    "bar = progressbar.ProgressBar()\n",
    "for k1, v1 in bar(word_seq_pairs.items()):\n",
    "    for k2, v2 in word_seq_pairs.items():\n",
    "        dist[v1[0], v2[0]] = utils.get_rhyme_similarity(v1[1], v2[1])>.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='precomputed',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(5, metric='precomputed')\n",
    "nn.fit(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('biodiversity', (4, ['B', 'AY2', 'OW0', 'D', 'AY0', 'V', 'ER1', 'S', 'AH0', 'T', 'IY0']))\n"
     ]
    }
   ],
   "source": [
    "print(list(word_seq_pairs.items())[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.kneighbors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
